{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'encounter_id', 'patient_nbr', 'age', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'metformin', 'repaglinide', 'nateglinide',\n",
      "       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
      "       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
      "       'miglitol', 'troglitazone', 'tolazamide', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'service_utilization', 'numchange', 'nummed',\n",
      "       'num_medications|time_in_hospital', 'num_medications|num_procedures',\n",
      "       'time_in_hospital|num_lab_procedures',\n",
      "       'num_medications|num_lab_procedures',\n",
      "       'num_medications|number_diagnoses', 'age|number_diagnoses',\n",
      "       'change|num_medications', 'number_diagnoses|time_in_hospital',\n",
      "       'num_medications|numchange', 'gender_1', 'admission_type_id_3',\n",
      "       'admission_type_id_4', 'admission_type_id_5',\n",
      "       'discharge_disposition_id_2', 'discharge_disposition_id_7',\n",
      "       'discharge_disposition_id_10', 'discharge_disposition_id_18',\n",
      "       'discharge_disposition_id_19', 'discharge_disposition_id_20',\n",
      "       'discharge_disposition_id_27', 'discharge_disposition_id_28',\n",
      "       'admission_source_id_4', 'admission_source_id_7',\n",
      "       'admission_source_id_8', 'admission_source_id_9',\n",
      "       'admission_source_id_11', 'max_glu_serum_0', 'max_glu_serum_1',\n",
      "       'A1Cresult_0', 'A1Cresult_1', 'level1_diag1_1.0', 'level1_diag1_2.0',\n",
      "       'level1_diag1_3.0', 'level1_diag1_4.0', 'level1_diag1_5.0',\n",
      "       'level1_diag1_6.0', 'level1_diag1_7.0', 'level1_diag1_8.0',\n",
      "       'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./content/processedBinary.csv')\n",
    "df.shape\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "67575    0\n",
       "67576    0\n",
       "67577    0\n",
       "67578    0\n",
       "67579    0\n",
       "Name: readmitted, Length: 67580, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_diagnoses', 'metformin', \n",
    "                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
    "                 'pioglitazone', 'rosiglitazone', 'acarbose', 'tolazamide', 'insulin', 'glyburide-metformin',\n",
    "                 'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other', 'gender_1', \n",
    "                 'admission_type_id_3', 'admission_type_id_5', 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n",
    "                 'discharge_disposition_id_10', 'discharge_disposition_id_18', 'admission_source_id_4',\n",
    "                 'admission_source_id_7', 'admission_source_id_9', 'max_glu_serum_0', 'max_glu_serum_1', 'A1Cresult_0',\n",
    "                 'A1Cresult_1', 'num_medications|time_in_hospital', 'num_medications|num_procedures',\n",
    "                 'time_in_hospital|num_lab_procedures', 'num_medications|num_lab_procedures', 'num_medications|number_diagnoses',\n",
    "                 'age|number_diagnoses', 'change|num_medications', 'number_diagnoses|time_in_hospital',\n",
    "                 'num_medications|numchange', 'level1_diag1_1.0', 'level1_diag1_2.0', 'level1_diag1_3.0', 'level1_diag1_4.0',\n",
    "                 'level1_diag1_5.0','level1_diag1_6.0', 'level1_diag1_7.0', 'level1_diag1_8.0']\n",
    "df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('readmitted',axis=1)\n",
    "Y=df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67580, 81)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "67575    0\n",
       "67576    0\n",
       "67577    0\n",
       "67578    0\n",
       "67579    0\n",
       "Name: readmitted, Length: 67580, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X=df.drop('readmitted',axis=1)\n",
    "# Y=df['readmitted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.9078129624149156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n",
    "# creating a RF classifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth=25, criterion = \"gini\", min_samples_split=10)  \n",
    "  \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "rf.fit(X_train, y_train)\n",
    "  \n",
    "# performing predictions on the test dataset\n",
    "y_pred = rf.predict(X_test)\n",
    "  \n",
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "  \n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION OF THE MODEL:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL OF THE MODEL:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078869488014205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create a gradient boosting classifier object\n",
    "gboost = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# train the model on the training data\n",
    "gboost.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "predictions = gboost.predict(X_test)\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = gboost.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078129624149156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create a decision tree classifier object\n",
    "dtree = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# train the model on the training data\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = dtree.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078129624149156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a logistic regression classifier object\n",
    "Lg = LogisticRegression()\n",
    "\n",
    "# train the model on the training data\n",
    "Lg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "predictions = Lg.predict(X_test)\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = Lg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.91\n",
      "Precision is 0.20\n",
      "Recall is 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rm = RandomForestClassifier(n_estimators = 10, max_depth=25, criterion = \"gini\", min_samples_split=10)\n",
    "rm.fit(X_train, y_train)\n",
    "\n",
    "rm_prd = rm.predict(X_test)\n",
    "pd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(rm_prd, name = 'Predict'), margins = True)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, rm_prd)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, rm_prd)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, rm_prd)))\n",
    "\n",
    "accuracy_rm = accuracy_score(y_test, rm_prd)\n",
    "precision_rm = precision_score(y_test, rm_prd)\n",
    "recall_rm = recall_score(y_test, rm_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.85\n",
      "Precision is 0.12\n",
      "Recall is 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree_pred = dtree.predict(X_test)\n",
    "pd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(dtree_pred, name = 'Predict'), margins = True)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, dtree_pred)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, dtree_pred)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, dtree_pred)))\n",
    "\n",
    "accuracy_dtree = accuracy_score(y_test, dtree_pred)\n",
    "precision_dtree = precision_score(y_test, dtree_pred)\n",
    "recall_dtree = recall_score(y_test, dtree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.91\n",
      "Precision is 0.00\n",
      "Recall is 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(fit_intercept=True, penalty='l2')\n",
    "logit.fit(X_train, y_train)\n",
    "logit_pred = logit.predict(X_test)\n",
    "pd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(logit_pred, name = 'Predict'), margins = True)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, logit_pred)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, logit_pred)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, logit_pred)))\n",
    "\n",
    "accuracy_logit = accuracy_score(y_test, logit_pred)\n",
    "precision_logit = precision_score(y_test, logit_pred)\n",
    "recall_logit = recall_score(y_test, logit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.91\n",
      "Precision is 0.31\n",
      "Recall is 0.01\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb =  xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_prediction = xgb.predict(X_test)\n",
    "pd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(xgb_prediction, name = 'Predict'), margins = True)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, xgb_prediction)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, xgb_prediction)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, xgb_prediction)))\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, xgb_prediction)\n",
    "precision_xgb = precision_score(y_test, xgb_prediction)\n",
    "recall_xgb = recall_score(y_test, xgb_prediction)\n",
    "#grid = GridSearchCV(estimator=SVM_MODEL, param_grid=parameters, cv=5)\n",
    "#grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This reshape error is often caused by passing a bad data matrix to SHAP. See https://github.com/slundberg/shap/issues/580",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:332\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 332\u001b[0m     phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49moriginal_model\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    333\u001b[0m         X, ntree_limit\u001b[39m=\u001b[39;49mtree_limit, pred_contribs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    334\u001b[0m         approx_contribs\u001b[39m=\u001b[39;49mapproximate, validate_features\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2163\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[0;32m   2162\u001b[0m dims \u001b[39m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 2163\u001b[0m _check_call(\n\u001b[0;32m   2164\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGBoosterPredictFromDMatrix(\n\u001b[0;32m   2165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   2166\u001b[0m         data\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   2167\u001b[0m         from_pystr_to_cstr(json\u001b[39m.\u001b[39;49mdumps(args)),\n\u001b[0;32m   2168\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(shape),\n\u001b[0;32m   2169\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(dims),\n\u001b[0;32m   2170\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(preds)\n\u001b[0;32m   2171\u001b[0m     )\n\u001b[0;32m   2172\u001b[0m )\n\u001b[0;32m   2173\u001b[0m \u001b[39mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [05:52:36] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api_utils.h:121: Check failed: std::accumulate(shape.cbegin(), shape.cend(), static_cast<bst_ulong>(1), std::multiplies<>{}) == chunksize * rows (7084 vs. 41492) : ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adith\\Desktop\\FInal year project\\deep learning\\MODEL_CLASSIFIERS.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# explain the model's predictions using SHAP\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mExplainer(xgb)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m shap_values \u001b[39m=\u001b[39m explainer(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# visualize the first prediction's explanation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m shap\u001b[39m.\u001b[39mplots\u001b[39m.\u001b[39mwaterfall_legacy(shap_values[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:217\u001b[0m, in \u001b[0;36mTree.__call__\u001b[1;34m(self, X, y, interactions, check_additivity)\u001b[0m\n\u001b[0;32m    214\u001b[0m     feature_names \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata_feature_names\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interactions:\n\u001b[1;32m--> 217\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshap_values(X, y\u001b[39m=\u001b[39;49my, from_call\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity, approximate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate)\n\u001b[0;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(v) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m:\n\u001b[0;32m    219\u001b[0m         v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(v, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# put outputs at the end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:337\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    332\u001b[0m     phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moriginal_model\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m    333\u001b[0m         X, ntree_limit\u001b[39m=\u001b[39mtree_limit, pred_contribs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    334\u001b[0m         approx_contribs\u001b[39m=\u001b[39mapproximate, validate_features\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 337\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThis reshape error is often caused by passing a bad data matrix to SHAP. \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m    338\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/slundberg/shap/issues/580\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m check_additivity \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel_output \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    341\u001b[0m     xgb_tree_limit \u001b[39m=\u001b[39m tree_limit \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_stacked_models \n",
      "\u001b[1;31mValueError\u001b[0m: This reshape error is often caused by passing a bad data matrix to SHAP. See https://github.com/slundberg/shap/issues/580"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "\n",
    "\"\"\"# train an XGBoost model\n",
    "X, y = shap.datasets.boston()\n",
    "model = xgboost.XGBRegressor().fit(X, y)\n",
    "\"\"\"\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(xgb)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall_legacy(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "             grow_policy='depthwise', importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
      "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
      "             max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, ...)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)\n"
     ]
    }
   ],
   "source": [
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "waterfall() got an unexpected keyword argument 'base_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adith\\Desktop\\FInal year project\\deep learning\\MODEL_CLASSIFIERS.ipynb Cell 21\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m shap_values \u001b[39m=\u001b[39m explainer(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# plot the SHAP values for the first 10 test data points\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m shap\u001b[39m.\u001b[39mplots\u001b[39m.\u001b[39mwaterfall(shap_values[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m], max_display\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, base_value\u001b[39m=\u001b[39mbase_value)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# create a summary plot of feature importances\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/MODEL_CLASSIFIERS.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m shap\u001b[39m.\u001b[39msummary_plot(shap_values, X_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: waterfall() got an unexpected keyword argument 'base_value'"
     ]
    }
   ],
   "source": [
    "# create an explainer object for our XGBoost model\n",
    "explainer = shap.Explainer(xgb)\n",
    "\n",
    "# calculate the average predicted value of the model\n",
    "base_value = y_test.mean()\n",
    "\n",
    "# calculate SHAP values for a set of test data\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# plot the SHAP values for the first 10 test data points\n",
    "shap.plots.waterfall(shap_values[0:10], max_display=10, base_value=base_value)\n",
    "\n",
    "# create a summary plot of feature importances\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# create a bar chart of feature importances\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
