{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RVts6Aogy7XF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import keras as k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL53n6PNzQnS",
        "outputId": "dc6ff779-3e5d-48ad-9904-2f151f5eb482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67580, 82)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv('./content/processedNew.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr8bAPEUzTi0",
        "outputId": "05735aac-4c35-4e12-fcfa-a1711d78b34a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    39826\n",
              "2    21625\n",
              "1     6129\n",
              "Name: readmitted, dtype: int64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['readmitted'].value_counts() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_set = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_diagnoses', 'metformin', \n",
        "                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
        "                 'pioglitazone', 'rosiglitazone', 'acarbose', 'tolazamide', 'insulin', 'glyburide-metformin',\n",
        "                 'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other', 'gender_1', \n",
        "                 'admission_type_id_3', 'admission_type_id_5', 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n",
        "                 'discharge_disposition_id_10', 'discharge_disposition_id_18', 'admission_source_id_4',\n",
        "                 'admission_source_id_7', 'admission_source_id_9', 'max_glu_serum_0', 'max_glu_serum_1', 'A1Cresult_0',\n",
        "                 'A1Cresult_1', 'num_medications|time_in_hospital', 'num_medications|num_procedures',\n",
        "                 'time_in_hospital|num_lab_procedures', 'num_medications|num_lab_procedures', 'num_medications|number_diagnoses',\n",
        "                 'age|number_diagnoses', 'change|num_medications', 'number_diagnoses|time_in_hospital',\n",
        "                 'num_medications|numchange', 'level1_diag1_1.0', 'level1_diag1_2.0', 'level1_diag1_3.0', 'level1_diag1_4.0',\n",
        "                 'level1_diag1_5.0','level1_diag1_6.0', 'level1_diag1_7.0', 'level1_diag1_8.0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IBNfwwwZF-I0"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_selection import mutual_info_classif\n",
        "# import matplotlib.pyplot as plt\n",
        "# importances=mutual_info_classif(X,df['readmitted'])\n",
        "# feat_importances = pd.Series(importances)\n",
        "# plt.figure().set_figheight(10)\n",
        "# feat_importances.plot(kind='barh',color =\"teal\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "oCjxjWVqJo6c"
      },
      "outputs": [],
      "source": [
        "# feature_set = ['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP4dLKKQMC3b",
        "outputId": "7d00f44e-8012-4d95-ea57-5a996533f9c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(feature_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dTjiwhCPNOpv"
      },
      "outputs": [],
      "source": [
        "X = df[feature_set]\n",
        "Y = pd.get_dummies(df['readmitted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FoYVZfyzaGQ",
        "outputId": "61693754-a492-4ec6-8486-00d17f965b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67580, 54)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk00I5HA7ee0",
        "outputId": "e8a3fd86-eeaa-42fe-d9c6-bf5a6188a93f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67580, 3)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5STUgzX87icZ",
        "outputId": "4e424c2a-d2af-4335-e766-5b657ee2c182"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67575</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67576</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67577</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67578</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67579</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67580 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2\n",
              "0      0  0  1\n",
              "1      1  0  0\n",
              "2      1  0  0\n",
              "3      1  0  0\n",
              "4      0  0  1\n",
              "...   .. .. ..\n",
              "67575  0  0  1\n",
              "67576  0  0  1\n",
              "67577  0  0  1\n",
              "67578  1  0  0\n",
              "67579  1  0  0\n",
              "\n",
              "[67580 rows x 3 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wTLzUk7FzdSb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X=df.drop('readmitted',axis=1)\n",
        "# Y=df['readmitted']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest Classfier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 3. RandomForestClassifier expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\adith\\Desktop\\FInal year project\\deep learning\\DL_MULTI_CLASS_CLASSIFICATION new.ipynb Cell 15\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m)  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Training the model on the training dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# fit function is used to train the model using the training sets as parameters\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# performing predictions on the test dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adith/Desktop/FInal%20year%20project/deep%20learning/DL_MULTI_CLASS_CLASSIFICATION%20new.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n",
            "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    332\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    333\u001b[0m )\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
            "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. RandomForestClassifier expected <= 2."
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# creating a RF classifier\n",
        "clf = RandomForestClassifier(n_estimators = 100)  \n",
        "  \n",
        "# Training the model on the training dataset\n",
        "# fit function is used to train the model using the training sets as parameters\n",
        "clf.fit(X_train, y_train)\n",
        "  \n",
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "  \n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics \n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9ZKdF6ZOzgib"
      },
      "outputs": [],
      "source": [
        "# Reshape input data for LSTM model\n",
        "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "y_train = np.reshape(y_train.values, (y_train.shape[0], 1, y_train.shape[1]))\n",
        "y_test = np.reshape(y_test.values, (y_test.shape[0], 1, y_test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-0so2a13zmxx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, ReLU, LeakyReLU\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Softmax\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "rvO44w6c2lCK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, input_shape=(1, X_train.shape[2])))\n",
        "# model.add(LSTM(20, activation='relu'))\n",
        "model.add(Dense(70,activation='relu'))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(70,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OgI3d6p2lpk",
        "outputId": "6fe96fc4-b579-4fc8-bafe-8b9199c8552c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1690/1690 [==============================] - 4s 2ms/step - loss: 0.9709 - accuracy: 0.5726 - val_loss: 0.8867 - val_accuracy: 0.5941\n",
            "Epoch 2/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8971 - accuracy: 0.5878 - val_loss: 0.8856 - val_accuracy: 0.5941\n",
            "Epoch 3/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8935 - accuracy: 0.5878 - val_loss: 0.8841 - val_accuracy: 0.5941\n",
            "Epoch 4/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8906 - accuracy: 0.5881 - val_loss: 0.8812 - val_accuracy: 0.5941\n",
            "Epoch 5/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8889 - accuracy: 0.5881 - val_loss: 0.8779 - val_accuracy: 0.5941\n",
            "Epoch 6/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8877 - accuracy: 0.5881 - val_loss: 0.8767 - val_accuracy: 0.5941\n",
            "Epoch 7/20\n",
            "1690/1690 [==============================] - 2s 1ms/step - loss: 0.8870 - accuracy: 0.5880 - val_loss: 0.8838 - val_accuracy: 0.5941\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ],
      "source": [
        "optimizer = k.optimizers.Adam(learning_rate=0.001)\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "# , callbacks=[es]\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eWShEj_2pgo",
        "outputId": "f43e5b91-594f-4f2d-d1c9-796d071ad60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.8838340044021606\n",
            "Test accuracy: 0.5941106677055359\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyBgashF2tS3",
        "outputId": "5d1dbc01-65f1-47b5-ddf1-05fd0f192831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.8959359526634216\n",
            "Train accuracy: 0.588117778301239\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Train loss:', score[0])\n",
        "print('Train accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
